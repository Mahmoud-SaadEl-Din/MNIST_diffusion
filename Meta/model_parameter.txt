Using device: cuda
model trained parameter:  1708201 , all parameters:  1708201
+----------------------------------------------------+------------+
|                      Modules                       | Parameters |
+----------------------------------------------------+------------+
|                  class_emb.weight                  |     40     |
|                model.conv_in.weight                |    1440    |
|                 model.conv_in.bias                 |     32     |
|        model.time_embedding.linear_1.weight        |    4096    |
|         model.time_embedding.linear_1.bias         |    128     |
|        model.time_embedding.linear_2.weight        |   16384    |
|         model.time_embedding.linear_2.bias         |    128     |
|     model.down_blocks.0.resnets.0.norm1.weight     |     32     |
|      model.down_blocks.0.resnets.0.norm1.bias      |     32     |
|     model.down_blocks.0.resnets.0.conv1.weight     |    9216    |
|      model.down_blocks.0.resnets.0.conv1.bias      |     32     |
| model.down_blocks.0.resnets.0.time_emb_proj.weight |    4096    |
|  model.down_blocks.0.resnets.0.time_emb_proj.bias  |     32     |
|     model.down_blocks.0.resnets.0.norm2.weight     |     32     |
|      model.down_blocks.0.resnets.0.norm2.bias      |     32     |
|     model.down_blocks.0.resnets.0.conv2.weight     |    9216    |
|      model.down_blocks.0.resnets.0.conv2.bias      |     32     |
|     model.down_blocks.0.resnets.1.norm1.weight     |     32     |
|      model.down_blocks.0.resnets.1.norm1.bias      |     32     |
|     model.down_blocks.0.resnets.1.conv1.weight     |    9216    |
|      model.down_blocks.0.resnets.1.conv1.bias      |     32     |
| model.down_blocks.0.resnets.1.time_emb_proj.weight |    4096    |
|  model.down_blocks.0.resnets.1.time_emb_proj.bias  |     32     |
|     model.down_blocks.0.resnets.1.norm2.weight     |     32     |
|      model.down_blocks.0.resnets.1.norm2.bias      |     32     |
|     model.down_blocks.0.resnets.1.conv2.weight     |    9216    |
|      model.down_blocks.0.resnets.1.conv2.bias      |     32     |
|   model.down_blocks.0.downsamplers.0.conv.weight   |    9216    |
|    model.down_blocks.0.downsamplers.0.conv.bias    |     32     |
| model.down_blocks.1.attentions.0.group_norm.weight |     64     |
|  model.down_blocks.1.attentions.0.group_norm.bias  |     64     |
|    model.down_blocks.1.attentions.0.to_q.weight    |    4096    |
|     model.down_blocks.1.attentions.0.to_q.bias     |     64     |
|    model.down_blocks.1.attentions.0.to_k.weight    |    4096    |
|     model.down_blocks.1.attentions.0.to_k.bias     |     64     |
|    model.down_blocks.1.attentions.0.to_v.weight    |    4096    |
|     model.down_blocks.1.attentions.0.to_v.bias     |     64     |
|  model.down_blocks.1.attentions.0.to_out.0.weight  |    4096    |
|   model.down_blocks.1.attentions.0.to_out.0.bias   |     64     |
| model.down_blocks.1.attentions.1.group_norm.weight |     64     |
|  model.down_blocks.1.attentions.1.group_norm.bias  |     64     |
|    model.down_blocks.1.attentions.1.to_q.weight    |    4096    |
|     model.down_blocks.1.attentions.1.to_q.bias     |     64     |
|    model.down_blocks.1.attentions.1.to_k.weight    |    4096    |
|     model.down_blocks.1.attentions.1.to_k.bias     |     64     |
|    model.down_blocks.1.attentions.1.to_v.weight    |    4096    |
|     model.down_blocks.1.attentions.1.to_v.bias     |     64     |
|  model.down_blocks.1.attentions.1.to_out.0.weight  |    4096    |
|   model.down_blocks.1.attentions.1.to_out.0.bias   |     64     |
|     model.down_blocks.1.resnets.0.norm1.weight     |     32     |
|      model.down_blocks.1.resnets.0.norm1.bias      |     32     |
|     model.down_blocks.1.resnets.0.conv1.weight     |   18432    |
|      model.down_blocks.1.resnets.0.conv1.bias      |     64     |
| model.down_blocks.1.resnets.0.time_emb_proj.weight |    8192    |
|  model.down_blocks.1.resnets.0.time_emb_proj.bias  |     64     |
|     model.down_blocks.1.resnets.0.norm2.weight     |     64     |
|      model.down_blocks.1.resnets.0.norm2.bias      |     64     |
|     model.down_blocks.1.resnets.0.conv2.weight     |   36864    |
|      model.down_blocks.1.resnets.0.conv2.bias      |     64     |
| model.down_blocks.1.resnets.0.conv_shortcut.weight |    2048    |
|  model.down_blocks.1.resnets.0.conv_shortcut.bias  |     64     |
|     model.down_blocks.1.resnets.1.norm1.weight     |     64     |
|      model.down_blocks.1.resnets.1.norm1.bias      |     64     |
|     model.down_blocks.1.resnets.1.conv1.weight     |   36864    |
|      model.down_blocks.1.resnets.1.conv1.bias      |     64     |
| model.down_blocks.1.resnets.1.time_emb_proj.weight |    8192    |
|  model.down_blocks.1.resnets.1.time_emb_proj.bias  |     64     |
|     model.down_blocks.1.resnets.1.norm2.weight     |     64     |
|      model.down_blocks.1.resnets.1.norm2.bias      |     64     |
|     model.down_blocks.1.resnets.1.conv2.weight     |   36864    |
|      model.down_blocks.1.resnets.1.conv2.bias      |     64     |
|   model.down_blocks.1.downsamplers.0.conv.weight   |   36864    |
|    model.down_blocks.1.downsamplers.0.conv.bias    |     64     |
| model.down_blocks.2.attentions.0.group_norm.weight |     64     |
|  model.down_blocks.2.attentions.0.group_norm.bias  |     64     |
|    model.down_blocks.2.attentions.0.to_q.weight    |    4096    |
|     model.down_blocks.2.attentions.0.to_q.bias     |     64     |
|    model.down_blocks.2.attentions.0.to_k.weight    |    4096    |
|     model.down_blocks.2.attentions.0.to_k.bias     |     64     |
|    model.down_blocks.2.attentions.0.to_v.weight    |    4096    |
|     model.down_blocks.2.attentions.0.to_v.bias     |     64     |
|  model.down_blocks.2.attentions.0.to_out.0.weight  |    4096    |
|   model.down_blocks.2.attentions.0.to_out.0.bias   |     64     |
| model.down_blocks.2.attentions.1.group_norm.weight |     64     |
|  model.down_blocks.2.attentions.1.group_norm.bias  |     64     |
|    model.down_blocks.2.attentions.1.to_q.weight    |    4096    |
|     model.down_blocks.2.attentions.1.to_q.bias     |     64     |
|    model.down_blocks.2.attentions.1.to_k.weight    |    4096    |
|     model.down_blocks.2.attentions.1.to_k.bias     |     64     |
|    model.down_blocks.2.attentions.1.to_v.weight    |    4096    |
|     model.down_blocks.2.attentions.1.to_v.bias     |     64     |
|  model.down_blocks.2.attentions.1.to_out.0.weight  |    4096    |
|   model.down_blocks.2.attentions.1.to_out.0.bias   |     64     |
|     model.down_blocks.2.resnets.0.norm1.weight     |     64     |
|      model.down_blocks.2.resnets.0.norm1.bias      |     64     |
|     model.down_blocks.2.resnets.0.conv1.weight     |   36864    |
|      model.down_blocks.2.resnets.0.conv1.bias      |     64     |
| model.down_blocks.2.resnets.0.time_emb_proj.weight |    8192    |
|  model.down_blocks.2.resnets.0.time_emb_proj.bias  |     64     |
|     model.down_blocks.2.resnets.0.norm2.weight     |     64     |
|      model.down_blocks.2.resnets.0.norm2.bias      |     64     |
|     model.down_blocks.2.resnets.0.conv2.weight     |   36864    |
|      model.down_blocks.2.resnets.0.conv2.bias      |     64     |
|     model.down_blocks.2.resnets.1.norm1.weight     |     64     |
|      model.down_blocks.2.resnets.1.norm1.bias      |     64     |
|     model.down_blocks.2.resnets.1.conv1.weight     |   36864    |
|      model.down_blocks.2.resnets.1.conv1.bias      |     64     |
| model.down_blocks.2.resnets.1.time_emb_proj.weight |    8192    |
|  model.down_blocks.2.resnets.1.time_emb_proj.bias  |     64     |
|     model.down_blocks.2.resnets.1.norm2.weight     |     64     |
|      model.down_blocks.2.resnets.1.norm2.bias      |     64     |
|     model.down_blocks.2.resnets.1.conv2.weight     |   36864    |
|      model.down_blocks.2.resnets.1.conv2.bias      |     64     |
|  model.up_blocks.0.attentions.0.group_norm.weight  |     64     |
|   model.up_blocks.0.attentions.0.group_norm.bias   |     64     |
|     model.up_blocks.0.attentions.0.to_q.weight     |    4096    |
|      model.up_blocks.0.attentions.0.to_q.bias      |     64     |
|     model.up_blocks.0.attentions.0.to_k.weight     |    4096    |
|      model.up_blocks.0.attentions.0.to_k.bias      |     64     |
|     model.up_blocks.0.attentions.0.to_v.weight     |    4096    |
|      model.up_blocks.0.attentions.0.to_v.bias      |     64     |
|   model.up_blocks.0.attentions.0.to_out.0.weight   |    4096    |
|    model.up_blocks.0.attentions.0.to_out.0.bias    |     64     |
|  model.up_blocks.0.attentions.1.group_norm.weight  |     64     |
|   model.up_blocks.0.attentions.1.group_norm.bias   |     64     |
|     model.up_blocks.0.attentions.1.to_q.weight     |    4096    |
|      model.up_blocks.0.attentions.1.to_q.bias      |     64     |
|     model.up_blocks.0.attentions.1.to_k.weight     |    4096    |
|      model.up_blocks.0.attentions.1.to_k.bias      |     64     |
|     model.up_blocks.0.attentions.1.to_v.weight     |    4096    |
|      model.up_blocks.0.attentions.1.to_v.bias      |     64     |
|   model.up_blocks.0.attentions.1.to_out.0.weight   |    4096    |
|    model.up_blocks.0.attentions.1.to_out.0.bias    |     64     |
|  model.up_blocks.0.attentions.2.group_norm.weight  |     64     |
|   model.up_blocks.0.attentions.2.group_norm.bias   |     64     |
|     model.up_blocks.0.attentions.2.to_q.weight     |    4096    |
|      model.up_blocks.0.attentions.2.to_q.bias      |     64     |
|     model.up_blocks.0.attentions.2.to_k.weight     |    4096    |
|      model.up_blocks.0.attentions.2.to_k.bias      |     64     |
|     model.up_blocks.0.attentions.2.to_v.weight     |    4096    |
|      model.up_blocks.0.attentions.2.to_v.bias      |     64     |
|   model.up_blocks.0.attentions.2.to_out.0.weight   |    4096    |
|    model.up_blocks.0.attentions.2.to_out.0.bias    |     64     |
|      model.up_blocks.0.resnets.0.norm1.weight      |    128     |
|       model.up_blocks.0.resnets.0.norm1.bias       |    128     |
|      model.up_blocks.0.resnets.0.conv1.weight      |   73728    |
|       model.up_blocks.0.resnets.0.conv1.bias       |     64     |
|  model.up_blocks.0.resnets.0.time_emb_proj.weight  |    8192    |
|   model.up_blocks.0.resnets.0.time_emb_proj.bias   |     64     |
|      model.up_blocks.0.resnets.0.norm2.weight      |     64     |
|       model.up_blocks.0.resnets.0.norm2.bias       |     64     |
|      model.up_blocks.0.resnets.0.conv2.weight      |   36864    |
|       model.up_blocks.0.resnets.0.conv2.bias       |     64     |
|  model.up_blocks.0.resnets.0.conv_shortcut.weight  |    8192    |
|   model.up_blocks.0.resnets.0.conv_shortcut.bias   |     64     |
|      model.up_blocks.0.resnets.1.norm1.weight      |    128     |
|       model.up_blocks.0.resnets.1.norm1.bias       |    128     |
|      model.up_blocks.0.resnets.1.conv1.weight      |   73728    |
|       model.up_blocks.0.resnets.1.conv1.bias       |     64     |
|  model.up_blocks.0.resnets.1.time_emb_proj.weight  |    8192    |
|   model.up_blocks.0.resnets.1.time_emb_proj.bias   |     64     |
|      model.up_blocks.0.resnets.1.norm2.weight      |     64     |
|       model.up_blocks.0.resnets.1.norm2.bias       |     64     |
|      model.up_blocks.0.resnets.1.conv2.weight      |   36864    |
|       model.up_blocks.0.resnets.1.conv2.bias       |     64     |
|  model.up_blocks.0.resnets.1.conv_shortcut.weight  |    8192    |
|   model.up_blocks.0.resnets.1.conv_shortcut.bias   |     64     |
|      model.up_blocks.0.resnets.2.norm1.weight      |    128     |
|       model.up_blocks.0.resnets.2.norm1.bias       |    128     |
|      model.up_blocks.0.resnets.2.conv1.weight      |   73728    |
|       model.up_blocks.0.resnets.2.conv1.bias       |     64     |
|  model.up_blocks.0.resnets.2.time_emb_proj.weight  |    8192    |
|   model.up_blocks.0.resnets.2.time_emb_proj.bias   |     64     |
|      model.up_blocks.0.resnets.2.norm2.weight      |     64     |
|       model.up_blocks.0.resnets.2.norm2.bias       |     64     |
|      model.up_blocks.0.resnets.2.conv2.weight      |   36864    |
|       model.up_blocks.0.resnets.2.conv2.bias       |     64     |
|  model.up_blocks.0.resnets.2.conv_shortcut.weight  |    8192    |
|   model.up_blocks.0.resnets.2.conv_shortcut.bias   |     64     |
|     model.up_blocks.0.upsamplers.0.conv.weight     |   36864    |
|      model.up_blocks.0.upsamplers.0.conv.bias      |     64     |
|  model.up_blocks.1.attentions.0.group_norm.weight  |     64     |
|   model.up_blocks.1.attentions.0.group_norm.bias   |     64     |
|     model.up_blocks.1.attentions.0.to_q.weight     |    4096    |
|      model.up_blocks.1.attentions.0.to_q.bias      |     64     |
|     model.up_blocks.1.attentions.0.to_k.weight     |    4096    |
|      model.up_blocks.1.attentions.0.to_k.bias      |     64     |
|     model.up_blocks.1.attentions.0.to_v.weight     |    4096    |
|      model.up_blocks.1.attentions.0.to_v.bias      |     64     |
|   model.up_blocks.1.attentions.0.to_out.0.weight   |    4096    |
|    model.up_blocks.1.attentions.0.to_out.0.bias    |     64     |
|  model.up_blocks.1.attentions.1.group_norm.weight  |     64     |
|   model.up_blocks.1.attentions.1.group_norm.bias   |     64     |
|     model.up_blocks.1.attentions.1.to_q.weight     |    4096    |
|      model.up_blocks.1.attentions.1.to_q.bias      |     64     |
|     model.up_blocks.1.attentions.1.to_k.weight     |    4096    |
|      model.up_blocks.1.attentions.1.to_k.bias      |     64     |
|     model.up_blocks.1.attentions.1.to_v.weight     |    4096    |
|      model.up_blocks.1.attentions.1.to_v.bias      |     64     |
|   model.up_blocks.1.attentions.1.to_out.0.weight   |    4096    |
|    model.up_blocks.1.attentions.1.to_out.0.bias    |     64     |
|  model.up_blocks.1.attentions.2.group_norm.weight  |     64     |
|   model.up_blocks.1.attentions.2.group_norm.bias   |     64     |
|     model.up_blocks.1.attentions.2.to_q.weight     |    4096    |
|      model.up_blocks.1.attentions.2.to_q.bias      |     64     |
|     model.up_blocks.1.attentions.2.to_k.weight     |    4096    |
|      model.up_blocks.1.attentions.2.to_k.bias      |     64     |
|     model.up_blocks.1.attentions.2.to_v.weight     |    4096    |
|      model.up_blocks.1.attentions.2.to_v.bias      |     64     |
|   model.up_blocks.1.attentions.2.to_out.0.weight   |    4096    |
|    model.up_blocks.1.attentions.2.to_out.0.bias    |     64     |
|      model.up_blocks.1.resnets.0.norm1.weight      |    128     |
|       model.up_blocks.1.resnets.0.norm1.bias       |    128     |
|      model.up_blocks.1.resnets.0.conv1.weight      |   73728    |
|       model.up_blocks.1.resnets.0.conv1.bias       |     64     |
|  model.up_blocks.1.resnets.0.time_emb_proj.weight  |    8192    |
|   model.up_blocks.1.resnets.0.time_emb_proj.bias   |     64     |
|      model.up_blocks.1.resnets.0.norm2.weight      |     64     |
|       model.up_blocks.1.resnets.0.norm2.bias       |     64     |
|      model.up_blocks.1.resnets.0.conv2.weight      |   36864    |
|       model.up_blocks.1.resnets.0.conv2.bias       |     64     |
|  model.up_blocks.1.resnets.0.conv_shortcut.weight  |    8192    |
|   model.up_blocks.1.resnets.0.conv_shortcut.bias   |     64     |
|      model.up_blocks.1.resnets.1.norm1.weight      |    128     |
|       model.up_blocks.1.resnets.1.norm1.bias       |    128     |
|      model.up_blocks.1.resnets.1.conv1.weight      |   73728    |
|       model.up_blocks.1.resnets.1.conv1.bias       |     64     |
|  model.up_blocks.1.resnets.1.time_emb_proj.weight  |    8192    |
|   model.up_blocks.1.resnets.1.time_emb_proj.bias   |     64     |
|      model.up_blocks.1.resnets.1.norm2.weight      |     64     |
|       model.up_blocks.1.resnets.1.norm2.bias       |     64     |
|      model.up_blocks.1.resnets.1.conv2.weight      |   36864    |
|       model.up_blocks.1.resnets.1.conv2.bias       |     64     |
|  model.up_blocks.1.resnets.1.conv_shortcut.weight  |    8192    |
|   model.up_blocks.1.resnets.1.conv_shortcut.bias   |     64     |
|      model.up_blocks.1.resnets.2.norm1.weight      |     96     |
|       model.up_blocks.1.resnets.2.norm1.bias       |     96     |
|      model.up_blocks.1.resnets.2.conv1.weight      |   55296    |
|       model.up_blocks.1.resnets.2.conv1.bias       |     64     |
|  model.up_blocks.1.resnets.2.time_emb_proj.weight  |    8192    |
|   model.up_blocks.1.resnets.2.time_emb_proj.bias   |     64     |
|      model.up_blocks.1.resnets.2.norm2.weight      |     64     |
|       model.up_blocks.1.resnets.2.norm2.bias       |     64     |
|      model.up_blocks.1.resnets.2.conv2.weight      |   36864    |
|       model.up_blocks.1.resnets.2.conv2.bias       |     64     |
|  model.up_blocks.1.resnets.2.conv_shortcut.weight  |    6144    |
|   model.up_blocks.1.resnets.2.conv_shortcut.bias   |     64     |
|     model.up_blocks.1.upsamplers.0.conv.weight     |   36864    |
|      model.up_blocks.1.upsamplers.0.conv.bias      |     64     |
|      model.up_blocks.2.resnets.0.norm1.weight      |     96     |
|       model.up_blocks.2.resnets.0.norm1.bias       |     96     |
|      model.up_blocks.2.resnets.0.conv1.weight      |   27648    |
|       model.up_blocks.2.resnets.0.conv1.bias       |     32     |
|  model.up_blocks.2.resnets.0.time_emb_proj.weight  |    4096    |
|   model.up_blocks.2.resnets.0.time_emb_proj.bias   |     32     |
|      model.up_blocks.2.resnets.0.norm2.weight      |     32     |
|       model.up_blocks.2.resnets.0.norm2.bias       |     32     |
|      model.up_blocks.2.resnets.0.conv2.weight      |    9216    |
|       model.up_blocks.2.resnets.0.conv2.bias       |     32     |
|  model.up_blocks.2.resnets.0.conv_shortcut.weight  |    3072    |
|   model.up_blocks.2.resnets.0.conv_shortcut.bias   |     32     |
|      model.up_blocks.2.resnets.1.norm1.weight      |     64     |
|       model.up_blocks.2.resnets.1.norm1.bias       |     64     |
|      model.up_blocks.2.resnets.1.conv1.weight      |   18432    |
|       model.up_blocks.2.resnets.1.conv1.bias       |     32     |
|  model.up_blocks.2.resnets.1.time_emb_proj.weight  |    4096    |
|   model.up_blocks.2.resnets.1.time_emb_proj.bias   |     32     |
|      model.up_blocks.2.resnets.1.norm2.weight      |     32     |
|       model.up_blocks.2.resnets.1.norm2.bias       |     32     |
|      model.up_blocks.2.resnets.1.conv2.weight      |    9216    |
|       model.up_blocks.2.resnets.1.conv2.bias       |     32     |
|  model.up_blocks.2.resnets.1.conv_shortcut.weight  |    2048    |
|   model.up_blocks.2.resnets.1.conv_shortcut.bias   |     32     |
|      model.up_blocks.2.resnets.2.norm1.weight      |     64     |
|       model.up_blocks.2.resnets.2.norm1.bias       |     64     |
|      model.up_blocks.2.resnets.2.conv1.weight      |   18432    |
|       model.up_blocks.2.resnets.2.conv1.bias       |     32     |
|  model.up_blocks.2.resnets.2.time_emb_proj.weight  |    4096    |
|   model.up_blocks.2.resnets.2.time_emb_proj.bias   |     32     |
|      model.up_blocks.2.resnets.2.norm2.weight      |     32     |
|       model.up_blocks.2.resnets.2.norm2.bias       |     32     |
|      model.up_blocks.2.resnets.2.conv2.weight      |    9216    |
|       model.up_blocks.2.resnets.2.conv2.bias       |     32     |
|  model.up_blocks.2.resnets.2.conv_shortcut.weight  |    2048    |
|   model.up_blocks.2.resnets.2.conv_shortcut.bias   |     32     |
|   model.mid_block.attentions.0.group_norm.weight   |     64     |
|    model.mid_block.attentions.0.group_norm.bias    |     64     |
|      model.mid_block.attentions.0.to_q.weight      |    4096    |
|       model.mid_block.attentions.0.to_q.bias       |     64     |
|      model.mid_block.attentions.0.to_k.weight      |    4096    |
|       model.mid_block.attentions.0.to_k.bias       |     64     |
|      model.mid_block.attentions.0.to_v.weight      |    4096    |
|       model.mid_block.attentions.0.to_v.bias       |     64     |
|    model.mid_block.attentions.0.to_out.0.weight    |    4096    |
|     model.mid_block.attentions.0.to_out.0.bias     |     64     |
|       model.mid_block.resnets.0.norm1.weight       |     64     |
|        model.mid_block.resnets.0.norm1.bias        |     64     |
|       model.mid_block.resnets.0.conv1.weight       |   36864    |
|        model.mid_block.resnets.0.conv1.bias        |     64     |
|   model.mid_block.resnets.0.time_emb_proj.weight   |    8192    |
|    model.mid_block.resnets.0.time_emb_proj.bias    |     64     |
|       model.mid_block.resnets.0.norm2.weight       |     64     |
|        model.mid_block.resnets.0.norm2.bias        |     64     |
|       model.mid_block.resnets.0.conv2.weight       |   36864    |
|        model.mid_block.resnets.0.conv2.bias        |     64     |
|       model.mid_block.resnets.1.norm1.weight       |     64     |
|        model.mid_block.resnets.1.norm1.bias        |     64     |
|       model.mid_block.resnets.1.conv1.weight       |   36864    |
|        model.mid_block.resnets.1.conv1.bias        |     64     |
|   model.mid_block.resnets.1.time_emb_proj.weight   |    8192    |
|    model.mid_block.resnets.1.time_emb_proj.bias    |     64     |
|       model.mid_block.resnets.1.norm2.weight       |     64     |
|        model.mid_block.resnets.1.norm2.bias        |     64     |
|       model.mid_block.resnets.1.conv2.weight       |   36864    |
|        model.mid_block.resnets.1.conv2.bias        |     64     |
|             model.conv_norm_out.weight             |     32     |
|              model.conv_norm_out.bias              |     32     |
|               model.conv_out.weight                |    288     |
|                model.conv_out.bias                 |     1      |
+----------------------------------------------------+------------+
Total Trainable Params: 1708201
